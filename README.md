# Credit Risk Modeling for Financial Inclusion ğŸš€

![CI/CD Pipeline](https://github.com/msultan001/credit-risk-model/actions/workflows/ci.yml/badge.svg)
![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![License](https://img.shields.io/badge/License-MIT-green)

A production-grade machine learning pipeline for credit risk assessment in emerging markets. This project demonstrates end-to-end MLOps practices, from data engineering to model deployment and interactive dashboards.

## ğŸ“Œ Business Context

### The Challenge
Financial institutions in emerging markets often lack traditional credit bureau data (FICO scores), leading to financial exclusion for millions of unbanked individuals. To bridge this gap, we use alternative dataâ€”specifically mobile money transaction historyâ€”to assess creditworthiness.

### Regulatory Compliance (Basel II)
This solution is designed with **Basel II** compliance in mind:
- **Interpretability**: We prioritize explainable models (Logistic Regression, SHAP values) to satisfy regulatory requirements for transparency.
- **Risk Management**: The model helps in calculating risk-weighted assets by providing accurate Probability of Default (PD) estimates.

### The Proxy Variable strategy
We derive a proxy for credit risk based on **RFM (Recency, Frequency, Monetary)** analysis:
- **High Risk**: Inactive customers (High Recency) with low usage (Low Frequency/Monetary).
- **Low Risk**: Active, consistent users.
This approach allows us to label potential defaulters even without historical loan data.

---

## ğŸ› ï¸ Project Structure

```bash
credit-risk-model/
â”œâ”€â”€ .github/workflows/   # CI/CD Pipeline (GitHub Actions)
â”œâ”€â”€ data/                # Data storage (gitignored)
â”œâ”€â”€ models/              # Serialized models and artifacts
â”œâ”€â”€ notebooks/           # Jupyter notebooks for experimentation
â”œâ”€â”€ reports/             # Generated reports and presentations
â”œâ”€â”€ src/                 # Source code
â”‚   â”œâ”€â”€ config.py        # Centralized configuration
â”‚   â”œâ”€â”€ dashboard.py     # Streamlit interactive dashboard
â”‚   â”œâ”€â”€ data_processing.py # Feature engineering pipeline
â”‚   â”œâ”€â”€ predict.py       # Inference engine
â”‚   â”œâ”€â”€ rfm_analysis.py  # Label engineering
â”‚   â””â”€â”€ train.py         # Model training & MLflow tracking
â”œâ”€â”€ tests/               # Unit tests
â”œâ”€â”€ Dockerfile           # Containerization
â”œâ”€â”€ requirements.txt     # Dependencies
â””â”€â”€ README.md            # You are here
```

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Docker (optional)

### Local Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/credit-risk-model.git
   cd credit-risk-model
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```
   *Note: Windows users might need to install C++ Build Tools for some libraries.*

4. **Run the Dashboard**
   ```bash
   streamlit run src/dashboard.py
   ```

---

## ğŸ’» Usage

### 1. Training the Model
Run the full training pipeline, which includes data loading, feature engineering, RFM analysis, oversampling (SMOTE), and model evaluation.
```bash
python src/train.py
```
*Artifacts will be saved to `models/` and metrics logged to MLflow.*

### 2. Making Predictions
Use the CLI to make predictions on new data:
```bash
python src/predict.py
```

### 3. Interactive Dashboard
Explore the data and explain model decisions:
```bash
streamlit run src/dashboard.py
```

---

## ğŸ“Š Key Features

- **Engineering Excellence**:
  - Modular, object-oriented code with type hinting.
  - Centralized configuration using `pydantic`.
  - Comprehensive unit tests with `pytest`.
  
- **MLOps Integration**:
  - Experiment tracking with **MLflow**.
  - CI/CD pipeline for automated testing.
  - Docker support for reproducible environments.

- **Advanced Modeling**:
  - **RFM Analysis** for unsupervised labeling.
  - **SMOTE** for handling class imbalance.
  - **WoE (Weight of Evidence)** transformation for categorical features.
  - **XGBoost** for high-performance classification.
  - **SHAP** values for model interpretability.

---

## ğŸ“ˆ Results

| Model | ROC-AUC | Precision | Recall | F1-Score |
|-------|---------|-----------|--------|----------|
| Logistic Regression | 0.82 | 0.65 | 0.78 | 0.71 |
| Random Forest | 0.88 | 0.72 | 0.75 | 0.73 |
| **XGBoost** | **0.91** | **0.78** | **0.80** | **0.79** |

*Note: Results based on initial validation set. Run `src/train.py` for latest metrics.*

---

## ğŸ“œ License
This project is licensed under the MIT License - see the LICENSE file for details.
